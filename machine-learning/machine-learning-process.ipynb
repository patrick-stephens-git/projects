{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19398da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964de82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 1: Define Problem\n",
    "##########################\n",
    "## Problem: ...\n",
    "## Goal: Generate ... Label\n",
    "## Labels Examples: Binary (True/False), Multiclass (X, Y, Z, etc...), Regression (Numerical Value)\n",
    "###################################################################################################\n",
    "## Outputs for Measuring Quality of Model Validation:\n",
    "### TRUE Positive: Validation Data Label = TRUE;  Machine Learning Label Output = TRUE \n",
    "## FALSE Positive: Validation Data Label = FALSE; Machine Learning Label Output = TRUE \n",
    "### TRUE Negative: Validation Data Label = FALSE; Machine Learning Label Output = FALSE \n",
    "## FALSE Negative: Validation Data Label = TRUE;  Machine Learning Label Output = FALSE \n",
    "## ^^^used for measuring the Model's Precision, Accuracy, Recall while validating the Model quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8718c44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 2: Collect & Split Dataset\n",
    "#####################################################\n",
    "########### If you have labels, then you are going to use a Supervised or Semi-supervised Learning Model\n",
    "#### If you do NOT have labels, then you are going to use an Unsupervised Learning Model\n",
    "## OR\n",
    "## If you have positive and negative outcomes, then you can use a Reinforcement Learning Model\n",
    "##############################################################################################\n",
    "## Feature: Column Name (e.g: Clicks)\n",
    "## Instance: Row Name (e.g: User ID)\n",
    "## Label: Row Values (e.g: 3)  \n",
    "## Aim for ideal dataset shape: 10 per 1 ratio of Instances per Features minimum\n",
    "################################################################################\n",
    "## Split the Collected Dataset:\n",
    "#### 85-90% of Collected Dataset: Exploratory Dataset\n",
    "###### Clean and Normalize Exploratory Dataset\n",
    "##############################################\n",
    "###### 85-90% of Exploratory Dataset: Training Dataset\n",
    "######################################################\n",
    "###### 10-15% of Exploratory Dataset: Debugging Dataset\n",
    "#######################################################\n",
    "###### 10-15% of Exploratory Dataset: Validation Dataset\n",
    "########################################################\n",
    "#### 10-15% of Collected Dataset: Final Testing Dataset\n",
    "#######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac381e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 3: Train Model\n",
    "#################################\n",
    "####### Epoch: total number of Instances in the Training Dataset\n",
    "## Batch Size: total number of Instances from the Training Dataset per Batch\n",
    "## Iterations: total number of Batches needed to iterate through the Training Dataset (Epoch)\n",
    "#############################################################################################\n",
    "## Train Model using the Training Dataset (Epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da21cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 4: Debug & Tune Model\n",
    "## Debug & Tune Model: Validate Model using the Debugging Dataset\n",
    "#### Review Machine Learning Label Output vs Debugging Dataset Label\n",
    "#### IF inspired THEN fix issues (dataset, hyperparameters, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5d2c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 5: Validate Model\n",
    "## Validate Model using the Validation Dataset\n",
    "## Review Accuracy, Precision, Recall Metrics\n",
    "## Do NOT review Review Machine Learning Label Output vs Debugging Dataset Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e877937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 6: Final Test on Model\n",
    "## Test Model using the Final Testing Dataset\n",
    "## Review Machine Learning Label Output vs Debugging Dataset Label\n",
    "## Review Accuracy, Precision, Recall Metrics\n",
    "## If the Model Fails, start over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddb0faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 7: Implementation & User Testing\n",
    "## Does this model positively impact key metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3b367d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 8: Tech Debt\n",
    "## Continue to retest the Model\n",
    "## (if applicable) Update the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c5be55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467c6c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed97fc23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
