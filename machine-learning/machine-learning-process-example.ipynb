{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd51d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Modules:\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "\n",
    "# Configure Modules:\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "288dd5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions:\n",
    "def predict_text_label_via_bag_of_words(list_of_text, df, percent_training_dataset_text_labeled_as_label_true, testing):\n",
    "    valid_words_list = []\n",
    "    for word in list_of_text:\n",
    "        if word in training_dataset_common_word_list:\n",
    "            valid_words_list.append(word)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    probability_label_false_list = []\n",
    "    probability_label_true_list = []\n",
    "    for valid_word in valid_words_list:\n",
    "        for index, row in df.iterrows():\n",
    "            word = row['word']\n",
    "            probability_label_true = row['prob spam = true']\n",
    "            probability_label_false = row['prob spam = false']\n",
    "            \n",
    "            if valid_word == word:\n",
    "                probability_label_false_list.append(probability_label_false)\n",
    "                probability_label_true_list.append(probability_label_true)\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "    word_df = pd.DataFrame(valid_words_list, columns=['word'])\n",
    "    probability_label_true_df = pd.DataFrame(probability_label_true_list, columns=['prob spam = true'])\n",
    "    probability_label_false_df = pd.DataFrame(probability_label_false_list, columns=['prob spam = false'])\n",
    "    predicted_labels_per_word_df = pd.concat([word_df, probability_label_true_df, probability_label_false_df], axis=1)\n",
    "    if testing == True:\n",
    "        print(predicted_labels_per_word_df)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    # Calculate spam True/False scores as sum of logs for all probabilities:\n",
    "    text_label_true_score = sum([np.log(p) for p in probability_label_true_list]) + np.log(percent_training_dataset_text_labeled_as_label_true)\n",
    "    text_label_false_score = sum([np.log(p) for p in probability_label_false_list]) + np.log(1-percent_training_dataset_text_labeled_as_label_true)\n",
    "    # Label as spam = True if text_label_true_score >= text_label_false_score\n",
    "    spam_score = (text_label_true_score >= text_label_false_score)\n",
    "    if testing == True:\n",
    "        print('Spam = True Score: {0}'.format(text_label_true_score))\n",
    "    else:\n",
    "        pass\n",
    "    text_label_true_score_list = [text_label_true_score]\n",
    "    if testing == True:\n",
    "        print('Spam = False Score: {0}'.format(text_label_false_score))\n",
    "    else:\n",
    "        pass\n",
    "    text_label_false_score_list = [text_label_false_score]\n",
    "    text = ' '.join(list_of_text) # Combine List Values into a Single String\n",
    "    if testing == True:\n",
    "        print('Text \"{0}\" is Spam: {1}'.format(text, spam_score))\n",
    "    else:\n",
    "        pass\n",
    "    text_label_score_list = [spam_score]\n",
    "    text_list = [text]\n",
    "    predictions_df = pd.DataFrame(text_list, columns=['text'])\n",
    "    text_label_score_df = pd.DataFrame(text_label_score_list, columns=['spam'])\n",
    "    spam_true_score_df = pd.DataFrame(text_label_true_score_list, columns=['spam true score'])\n",
    "    spam_false_score_df = pd.DataFrame(text_label_false_score_list, columns=['spam false score'])\n",
    "    predictions_df = pd.concat([predictions_df, text_label_score_df, spam_true_score_df, spam_false_score_df], axis=1)\n",
    "    return predictions_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45aa0077",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 1: Define Problem\n",
    "##########################\n",
    "## Problem: ...\n",
    "## Goal: Generate ... Label\n",
    "## Labels Examples: Binary (True/False), Multiclass (X, Y, Z, etc...), Regression (Numerical Value)\n",
    "###################################################################################################\n",
    "## Outputs for Measuring Quality of Model Validation:\n",
    "### TRUE Positive: Validation Data Label = TRUE;  Machine Learning Label Output = TRUE \n",
    "## FALSE Positive: Validation Data Label = FALSE; Machine Learning Label Output = TRUE \n",
    "### TRUE Negative: Validation Data Label = FALSE; Machine Learning Label Output = FALSE \n",
    "## FALSE Negative: Validation Data Label = TRUE;  Machine Learning Label Output = FALSE \n",
    "## ^^^used for measuring the Model's Precision, Accuracy, Recall while validating the Model quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b71ae9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected Dataset shape (X): (5572,) (instances, features)\n",
      "Collected Dataset Labels shape (y): (5572,) (labels)\n",
      "Exploratory Dataset: Training Dataset Features shape (X_train): (4736,) (instances, features)\n",
      "Exploratory Dataset: Training Dataset Labels shape (y_train): (4736,) (labels)\n",
      "Exploratory Dataset: Validation Dataset Features shape (X_test): (836,) (instances, features)\n",
      "Exploratory Dataset: Validation Dataset Labels shape (y_test): (836,) (labels)\n",
      "\n",
      "Training Dataset: (Exploratory Dataset)\n",
      "% of Training Dataset Instances Labeled as \"label\": 13.492397964000702%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>we regret to inform u that the nhs has made a mistakeu were never actually bornplease report 2 yor local hospital 2b terminatedwe r sorry 4 the inconvenience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4 tacos  1 rajas burrito right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>alright babe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>dear umma she called me now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>well theres a pattern emerging of my friends telling me to drive up and come smoke with them and then telling me that im a weed fiendmake them smoke too muchimpede their doing other things so you see how im hesitant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>after completed degree there is no use in joining finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>k ill take care of it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>interflora  åòits not too late to order interflora flowers for christmas call 0800 505060 to place your order before midnight tomorrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>sfine anytime all the best with it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>will purchase d stuff today and mail to you do you have a po box number</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spam  \\\n",
       "0   0.0   \n",
       "1   0.0   \n",
       "2   0.0   \n",
       "3   0.0   \n",
       "4   0.0   \n",
       "5   0.0   \n",
       "6   0.0   \n",
       "7   1.0   \n",
       "8   0.0   \n",
       "9   0.0   \n",
       "\n",
       "                                                                                                                                                                                                                      text  \n",
       "0                                                            we regret to inform u that the nhs has made a mistakeu were never actually bornplease report 2 yor local hospital 2b terminatedwe r sorry 4 the inconvenience  \n",
       "1                                                                                                                                                                                           4 tacos  1 rajas burrito right  \n",
       "2                                                                                                                                                                                                             alright babe  \n",
       "3                                                                                                                                                                                             dear umma she called me now   \n",
       "4  well theres a pattern emerging of my friends telling me to drive up and come smoke with them and then telling me that im a weed fiendmake them smoke too muchimpede their doing other things so you see how im hesitant  \n",
       "5                                                                                                                                                                after completed degree there is no use in joining finance  \n",
       "6                                                                                                                                                                                                    k ill take care of it  \n",
       "7                                                                                   interflora  åòits not too late to order interflora flowers for christmas call 0800 505060 to place your order before midnight tomorrow  \n",
       "8                                                                                                                                                                                       sfine anytime all the best with it  \n",
       "9                                                                                                                                                  will purchase d stuff today and mail to you do you have a po box number  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Step 2: Collect & Split Collected Dataset; Clean & Normalize Exploratory Dataset\n",
    "#####################################################\n",
    "## Feature: Text\n",
    "## Instance: label\n",
    "## Label: True/False\n",
    "df = pd.read_csv('spam-labels.csv', encoding='ISO-8859-1')\n",
    "df = df[['spam', 'text']] # label = label\n",
    "df['spam'] = df['spam'].apply(lambda row: True if row == 'spam' else False)\n",
    "df['text'] = df['text'].apply(lambda row: row.lower().translate(str.maketrans('', '', string.punctuation)))\n",
    "##############################\n",
    "## Split the Collected Dataset:\n",
    "X = df.loc[:, 'text'].values\n",
    "print('Collected Dataset shape (X): {0} (instances, features)'.format(X.shape))\n",
    "y = df.loc[:, 'spam'].values.astype(np.float32).ravel() # Outcome = 1/0; Success/Failure\n",
    "print('Collected Dataset Labels shape (y): {0} (labels)'.format(y.shape))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42) # From Module: sklearn.model_selection; test_size = % allocated to Validation Dataset\n",
    "# #####################################################\n",
    "# #### 85-90% of Collected Dataset: Exploratory Dataset\n",
    "# #####################################################\n",
    "# ###### Clean and Normalize Exploratory Dataset\n",
    "########################################################\n",
    "######## 85-90% of Exploratory Dataset: Training Dataset\n",
    "print('Exploratory Dataset: Training Dataset Features shape (X_train): {0} (instances, features)'.format(X_train.shape))\n",
    "X_train_df = pd.DataFrame(X_train, columns = ['text'])\n",
    "print('Exploratory Dataset: Training Dataset Labels shape (y_train): {0} (labels)'.format(y_train.shape))\n",
    "y_train_df = pd.DataFrame(y_train, columns = ['spam'])\n",
    "training_dataset = pd.concat([y_train_df, X_train_df], axis=1)\n",
    "training_dataset_label_true = training_dataset[training_dataset['spam'] == 1.0]\n",
    "training_dataset_label_false = training_dataset[training_dataset['spam'] == 0.0]\n",
    "#######################################################\n",
    "## Clean & Normalize Exploratory Dataset: (label = TRUE)\n",
    "training_dataset_label_true_list = training_dataset_label_true['text'].astype(str).tolist() # Turn DataFrame to List\n",
    "training_dataset_label_true_string = ''.join(training_dataset_label_true_list) # Combine List Values into a Single String\n",
    "# print(training_dataset_label_true_string)\n",
    "training_dataset_label_true_string = training_dataset_label_true_string.translate(str.maketrans('', '', string.punctuation)) ## Remove Punctuation Characters\n",
    "training_dataset_label_true_string = training_dataset_label_true_string.replace('\\n','') ## Remove Line Breaks\n",
    "training_dataset_label_true_string = re.sub(r'[0-9]+', '', training_dataset_label_true_string) ## Remove Numerical Characters\n",
    "training_dataset_label_true_string = training_dataset_label_true_string.lower() ## Lowercase Characters\n",
    "stop_words = set(stopwords.words('english'))\n",
    "training_dataset_label_true_string = word_tokenize(training_dataset_label_true_string)\n",
    "training_dataset_label_true_string = [word for word in training_dataset_label_true_string if word not in stop_words] ## Remove Stop words\n",
    "training_dataset_label_true_string = ' '.join(training_dataset_label_true_string)\n",
    "########################################################\n",
    "## Clean & Normalize Exploratory Dataset: (label = FALSE)\n",
    "training_dataset_label_false_list = training_dataset_label_false['text'].astype(str).tolist() # Turn DataFrame to List\n",
    "training_dataset_label_false_string = ''.join(training_dataset_label_false_list) # Combine List Values into a Single String\n",
    "training_dataset_label_false_string = training_dataset_label_false_string.translate(str.maketrans('', '', string.punctuation)) ## Remove Punctuation Characters\n",
    "training_dataset_label_false_string = training_dataset_label_false_string.replace('\\n','') ## Remove Line Breaks\n",
    "training_dataset_label_false_string = re.sub(r'[0-9]+', '', training_dataset_label_false_string) ## Remove Numerical Characters\n",
    "training_dataset_label_false_string = training_dataset_label_false_string.lower() ## Lowercase Characters\n",
    "stop_words = set(stopwords.words('english'))\n",
    "training_dataset_label_false_string = word_tokenize(training_dataset_label_false_string)\n",
    "training_dataset_label_false_string = [word for word in training_dataset_label_false_string if word not in stop_words] ## Remove Stop words\n",
    "training_dataset_label_false_string = ' '.join(training_dataset_label_false_string)\n",
    "############################################\n",
    "## Get a List of All Text where spam == True\n",
    "training_dataset_label_true_word_list = training_dataset_label_true_string.split()\n",
    "#############################################\n",
    "## Get a List of All Text where spam == False\n",
    "training_dataset_label_false_word_list = training_dataset_label_false_string.split()\n",
    "#############################\n",
    "## Get a List of Common Words where spam == True AND spam == False\n",
    "training_dataset_common_word_list = set(training_dataset_label_true_word_list).intersection(set(training_dataset_label_false_word_list))\n",
    "#########################################################\n",
    "######## 10-15% of Exploratory Dataset: Debugging Dataset\n",
    "#########################################################\n",
    "######## 10-15% of Exploratory Dataset: Validation Dataset\n",
    "print('Exploratory Dataset: Validation Dataset Features shape (X_test): {0} (instances, features)'.format(X_test.shape))\n",
    "X_test_df = pd.DataFrame(X_test, columns = ['text'])\n",
    "print('Exploratory Dataset: Validation Dataset Labels shape (y_test): {0} (labels)'.format(y_test.shape))\n",
    "y_test_df = pd.DataFrame(y_test, columns = ['spam'])\n",
    "#########################################################\n",
    "###### 10-15% of Collected Dataset: Final Testing Dataset\n",
    "#########################################################\n",
    "print('\\nTraining Dataset: (Exploratory Dataset)')\n",
    "y_train_df = pd.DataFrame(y_train, columns = ['spam'])\n",
    "percent_training_dataset_text_labeled_as_label_true = y_train_df['spam'].mean()\n",
    "print('% of Training Dataset Instances Labeled as \"label\": {0}%'.format(percent_training_dataset_text_labeled_as_label_true * 100))\n",
    "training_dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6df1518f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>prob spam = true</th>\n",
       "      <th>prob spam = false</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>call</td>\n",
       "      <td>0.031575</td>\n",
       "      <td>0.005776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>å£</td>\n",
       "      <td>0.024374</td>\n",
       "      <td>0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>free</td>\n",
       "      <td>0.017948</td>\n",
       "      <td>0.001276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>txt</td>\n",
       "      <td>0.014070</td>\n",
       "      <td>0.000383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>u</td>\n",
       "      <td>0.013073</td>\n",
       "      <td>0.025176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>ur</td>\n",
       "      <td>0.012076</td>\n",
       "      <td>0.006733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>mobile</td>\n",
       "      <td>0.011522</td>\n",
       "      <td>0.000415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>text</td>\n",
       "      <td>0.010747</td>\n",
       "      <td>0.001787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>stop</td>\n",
       "      <td>0.009750</td>\n",
       "      <td>0.000862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>reply</td>\n",
       "      <td>0.009417</td>\n",
       "      <td>0.000830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  prob spam = true  prob spam = false\n",
       "352    call          0.031575           0.005776\n",
       "741      å£          0.024374           0.000128\n",
       "629    free          0.017948           0.001276\n",
       "298     txt          0.014070           0.000383\n",
       "216       u          0.013073           0.025176\n",
       "159      ur          0.012076           0.006733\n",
       "382  mobile          0.011522           0.000415\n",
       "685    text          0.010747           0.001787\n",
       "626    stop          0.009750           0.000862\n",
       "470   reply          0.009417           0.000830"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Step 3: Train Model using the Exploratory Dataset: Training Dataset\n",
    "#################################\n",
    "####### Epoch: total number of Instances in the Training Dataset\n",
    "## Batch Size: total number of Instances from the Training Dataset per Batch\n",
    "## Iterations: total number of Batches needed to iterate through the Training Dataset (Epoch)\n",
    "#############################################################################################\n",
    "## Train Model using the Training Dataset (Exploratory Dataset) (Epoch)\n",
    "####################################################\n",
    "## Create \"Bag of Words\" Dictionary\n",
    "probability_label_true_list = []\n",
    "for common_word in training_dataset_common_word_list:\n",
    "    probability_label_true = training_dataset_label_true_word_list.count(common_word) / len(training_dataset_label_true_word_list)\n",
    "    probability_label_true_list.append(probability_label_true)\n",
    "####################################################\n",
    "## Create \"Bag of Words\" Dictionary\n",
    "probability_label_false_list = []\n",
    "for common_word in training_dataset_common_word_list:\n",
    "    probability_label_false = training_dataset_label_false_word_list.count(common_word) / len(training_dataset_label_false_word_list)\n",
    "    probability_label_false_list.append(probability_label_false)\n",
    "word_df = pd.DataFrame(training_dataset_common_word_list, columns=['word'])\n",
    "prob_label_true_df = pd.DataFrame(probability_label_true_list, columns=['prob spam = true'])\n",
    "prob_label_false_df = pd.DataFrame(probability_label_false_list, columns=['prob spam = false'])\n",
    "label_probabilities_df = pd.concat([word_df, prob_label_true_df, prob_label_false_df], axis=1)\n",
    "label_probabilities_df.sort_values(['prob spam = true'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1af85e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    word  prob spam = true  prob spam = false\n",
      "0  youre          0.000222           0.001276\n",
      "1  close          0.000443           0.000255\n",
      "2   free          0.017948           0.001276\n",
      "3   year          0.000554           0.001053\n",
      "Spam = True Score: -29.65802642220085\n",
      "Spam = False Score: -28.601704308913586\n",
      "Text \"youre so close to winning free internet for a year\" is Spam: False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "      <th>spam true score</th>\n",
       "      <th>spam false score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>youre so close to winning free internet for a year</td>\n",
       "      <td>False</td>\n",
       "      <td>-29.658026</td>\n",
       "      <td>-28.601704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text   spam  spam true score  \\\n",
       "0  youre so close to winning free internet for a year  False       -29.658026   \n",
       "\n",
       "   spam false score  \n",
       "0        -28.601704  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Step 4: Debug & Tune Model\n",
    "## Debug & Tune Model: Validate Model using the Debugging Dataset\n",
    "#### Review Machine Learning Label Output vs Debugging Dataset Label\n",
    "#### IF inspired THEN fix issues (dataset, hyperparameters, etc.)\n",
    "testing = True\n",
    "text = 'youre so close to winning free internet for a year'\n",
    "predictions_df = predict_text_label_via_bag_of_words(text.split(), label_probabilities_df, percent_training_dataset_text_labeled_as_label_true, testing)\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bbb9433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 77\n",
      "FP: 31\n",
      "TN: 639\n",
      "FP: 5\n",
      "\n",
      "Spam Detection Accuracy: 0.1023936170212766%\n",
      "Spam Detection Precision: 0.7129629629629629%\n",
      "Spam Detection Recall: 0.9390243902439024%\n"
     ]
    }
   ],
   "source": [
    "## Step 5: Validate Model\n",
    "## Validate Model using the Validation Dataset\n",
    "## Review Accuracy, Precision, Recall Metrics\n",
    "## Do NOT review Review Machine Learning Label Output vs Debugging Dataset Label\n",
    "testing = False\n",
    "X_test_df = pd.DataFrame(X_test, columns=['text'])\n",
    "X_test_list = X_test_df['text'].to_list()\n",
    "\n",
    "validation_predictions_df = pd.DataFrame()\n",
    "for text in X_test_list:\n",
    "    predictions_df = predict_text_label_via_bag_of_words(text.split(), label_probabilities_df, percent_training_dataset_text_labeled_as_label_true, testing)\n",
    "    validation_predictions_df = validation_predictions_df.append(predictions_df)\n",
    "\n",
    "validation_predictions_df = validation_predictions_df.drop(columns=['spam true score','spam false score'])\n",
    "validation_predictions_df.reset_index(drop=True, inplace=True)\n",
    "validation_predictions_df.head()\n",
    "    \n",
    "validation_dataset = pd.concat([X_test_df, y_test_df], axis=1)\n",
    "label_boolean_list = []\n",
    "for index, row in validation_dataset.iterrows():\n",
    "    spam = row['spam']\n",
    "    if spam == 1.0:\n",
    "        label_boolean_list.append(True)\n",
    "    else:\n",
    "        label_boolean_list.append(False)\n",
    "\n",
    "validation_dataset = validation_dataset.drop(columns=['spam'])\n",
    "label_boolean_df = pd.DataFrame(label_boolean_list, columns=['spam'])\n",
    "validation_dataset = pd.concat([validation_dataset, label_boolean_df], axis=1)\n",
    "\n",
    "label_prediction_true_df = validation_predictions_df[(validation_predictions_df['spam'] == True)]\n",
    "label_prediction_false_df = validation_predictions_df[(validation_predictions_df['spam'] == False)]\n",
    "validation_dataset_true_df = validation_dataset[(validation_dataset['spam'] == True)]\n",
    "validation_dataset_false_df = validation_dataset[(validation_dataset['spam'] == False)]\n",
    "\n",
    "validation_predictions_df.compare(validation_dataset, keep_equal=False)\n",
    "\n",
    "true_positives_df = pd.merge(validation_dataset_true_df, label_prediction_true_df, how='left', on='text') # text = spam; prediction = spam\n",
    "false_positives_df = pd.merge(label_prediction_true_df, validation_dataset_false_df, how='left', on='text') # text = spam; prediction = spam\n",
    "true_negatives_df = pd.merge(validation_dataset_false_df, label_prediction_false_df, how='left', on='text') # text = spam; prediction = spam\n",
    "false_negatives_df = pd.merge(label_prediction_false_df, validation_dataset_true_df, how='left', on='text') # text = spam; prediction = spam\n",
    "\n",
    "true_positives_count = true_positives_df[(true_positives_df['spam_y'] == True)]['spam_y'].count()\n",
    "false_positives_count = false_positives_df[(false_positives_df['spam_y'] == False)]['spam_y'].count()\n",
    "true_negatives_count = true_negatives_df[(true_negatives_df['spam_y'] == False)]['spam_y'].count()\n",
    "false_negatives_count = false_negatives_df[(false_negatives_df['spam_y'] == True)]['spam_y'].count()\n",
    "\n",
    "print('TP: {0}'.format(true_positives_count))\n",
    "print('FP: {0}'.format(false_positives_count))\n",
    "print('TN: {0}'.format(true_negatives_count))\n",
    "print('FP: {0}'.format(false_negatives_count))\n",
    "\n",
    "accuracy = true_positives_count / (true_positives_count + false_positives_count + true_negatives_count + false_negatives_count)\n",
    "precision = true_positives_count / (true_positives_count + false_positives_count)\n",
    "recall = true_positives_count / (true_positives_count + false_negatives_count)\n",
    "print('\\nSpam Detection Accuracy: {0}%'.format(accuracy)) # Accuracy = TP / P\n",
    "print('Spam Detection Precision: {0}%'.format(precision)) # Precision = TP / (TP + FP)\n",
    "print('Spam Detection Recall: {0}%'.format(recall)) # Recall = TP / (TP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3293cc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 6: Final Test on Model\n",
    "## Test Model using the Final Testing Dataset\n",
    "## Review Machine Learning Label Output vs Debugging Dataset Label\n",
    "## Review Accuracy, Precision, Recall Metrics\n",
    "## If the Model Fails, start over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18ed01cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 7: Implementation & User Testing\n",
    "## Does this model positively impact key metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4465a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 8: Tech Debt\n",
    "## Continue to retest the Model\n",
    "## (if applicable) Update the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176fff23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c351b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e198528",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
